{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC\n",
    "- Datetime in python\n",
    "- 3 objects: Date, Time, DateTime  (from datetime import datetime, date, time)\n",
    "- time deltas (from datetime import timedelta)\n",
    "  - operations:\n",
    "    - minus, plus, multiply, divide\n",
    "- convert between datetime and string and vice versa\n",
    "  - `datetime.now().isoformat()` convert to string\n",
    "  - `datetime.strptime('21/11/06 16:30', '%d/%m/%y %H:%M')` convert to datetime\n",
    "  - `import dateutil.parser; dateutil.parser.parse('21/11-06 16:30')` easy (forgiving) datatime parsing lib\n",
    "- Pandas\n",
    "  - Series and DataFrame\n",
    "  - Series\n",
    "    - 1 dimensional data structure\n",
    "    - \n",
    "  - DataFrame\n",
    "    - 2 dimensional data structure\n",
    "    - `pandas.DataFrame( data, index, columns, dtype, copy)`\n",
    "    - columns can be of different types\n",
    "    - data can be lists, dicts, maps, ndarrays.\n",
    "- pd.Series("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime in Python\n",
    "\n",
    "This intro to handling *dates* and *times* in Python is based on the documentation of the standard library's `datetime` module https://docs.python.org/3.6/library/datetime.html.\n",
    "\n",
    "The datetime module supplies classes for manipulating *dates* and *times* in both simple and complex ways. While date and time arithmetic is supported, the focus of the implementation is on efficient attribute extraction for output formatting and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Objects\n",
    "\n",
    "A date object represents a date (year, month and day) in an idealized calendar, the current Gregorian calendar indefinitely extended in both directions. January 1 of year 1 is called day number 1, January 2 of year 1 is called day number 2, and so on. This matches the definition of the \"proleptic Gregorian\" calendar in Dershowitz and Reingoldâ€™s book Calendrical Calculations, where it is the base calendar for all computations. See the book for algorithms for converting between proleptic Gregorian ordinals and many other calendar systems. Alternatively, you can have a look at the paper describing what is extended in the book:\n",
    "http://www.cs.tau.ac.il/~nachumd/papers/cc-paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 3, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "today = date.today()\n",
    "print(today)\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 10, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = date(today.year, 10, 2)\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_lecture = date(today.year, 10, 9)\n",
    "time_to_next_lecture = abs(next_lecture - today)\n",
    "time_to_next_lecture.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "# see the timedelta documentation:\n",
    "# https://docs.python.org/3.6/library/datetime.html#timedelta-objects\n",
    "\n",
    "next_lecture = date(today.year, 10, 2) + timedelta(5)\n",
    "time_to_next_lecture = abs(next_lecture - today)\n",
    "time_to_next_lecture.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02/10/2019'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today.strftime(\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wednesday 02. October 2019'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today.strftime(\"%A %d. %B %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Objects\n",
    "\n",
    "A time object represents a (local) time of day, independent of any particular day. In our coure I will not consider times with respect to different time zones. In case you need to add information about which time zone a `time` refers, please read https://docs.python.org/3.4/library/datetime.html#tzinfo-objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12:10:30'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, date, time\n",
    "\n",
    "\n",
    "t = time(12, 10, 30)\n",
    "t.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:10:30\n",
      "The time is 12:10.\n"
     ]
    }
   ],
   "source": [
    "print(t.strftime('%H:%M:%S'))\n",
    "\n",
    "print('The time is {:%H:%M}.'.format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 3, 3, 12, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, date, time\n",
    "\n",
    "\n",
    "d = date.today()\n",
    "t = time(12, 30)\n",
    "datetime.combine(d, t) # todays date combined with time: 12:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-03 16:18:01.947856\n",
      "2019-03-03 16:18:01\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(now)\n",
    "now = now.replace(microsecond=0)\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 3, 3, 14, 42, 30, 847761)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the year is 2019, the week is 9 and it is the 7th day\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "ic = now.isocalendar()\n",
    "print('the year is {}, the week is {} and it is the {}th day'.format(ic[0], ic[1],ic[2]))\n",
    "week_number = ic[1]\n",
    "print(week_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sunday, 03. March 2019 04:18PM'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.strftime(\"%A, %d. %B %Y %I:%M%p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The day is 03, the month is March, the time is 03:42PM.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'The {1} is {0:%d}, the {2} is {0:%B}, the {3} is {0:%I:%M%p}.'.format(now, \"day\", \"month\", \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-06-10 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10-06-2010 week: 23'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = datetime.strptime('10 Jun 2010', '%d %b %Y')\n",
    "print(d)\n",
    "d.strftime('%d-%m-%Y week: %U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timedeltas\n",
    "\n",
    "A `timedelta` object represents a duration, the difference between two dates or times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "d = timedelta(microseconds=5)\n",
    "(d.days, d.seconds, d.microseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(-1, 68400)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedelta(hours=-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with `timedelta`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_as_delta: 365 days, 0:00:00\n",
      "2018-03-03 15:42:31.259717\n",
      "2020-03-02 15:42:31.259846\n",
      "The two year difference is equivalent to 730 days or to 63072000.000129 seconds\n"
     ]
    }
   ],
   "source": [
    "year_as_delta = timedelta(days=365)\n",
    "print('year_as_delta:',year_as_delta)\n",
    "another_year_delta = timedelta(weeks=40, days=84, hours=23, minutes=50, seconds=600)  # adds up to 365 days\n",
    "\n",
    "last_year = datetime.now() - year_as_delta\n",
    "next_year = datetime.now() - year_as_delta + (2 *another_year_delta)\n",
    "print(last_year)\n",
    "print(next_year)\n",
    "\n",
    "two_year_delta = next_year - last_year\n",
    "print('The two year difference is equivalent to {} days or to {} seconds'.format(\n",
    "    two_year_delta.days, two_year_delta.total_seconds()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Strings to Times and Vice Versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-03-03T15:42:31.312044'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2006, 11, 21, 16, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = datetime.strptime('21/11/06 16:30', '%d/%m/%y %H:%M')\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06-11-21 16:30'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.strftime('%y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Arbitrary Dates from Strings\n",
    "\n",
    "The `dateutil.parser` module offers a generic date/time string parser which is able to parse most known formats to represent a date and/or time.\n",
    "\n",
    "The module attempts to be forgiving with regards to unlikely input formats, returning a datetime object even for dates which are ambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2006, 11, 21, 16, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dateutil.parser\n",
    "\n",
    "\n",
    "dateutil.parser.parse('21/11-06 16:30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class exercise with dates\n",
    "Create a function: getMeetingDates in a module called myUtilities.py\n",
    "- the function must take 3 arguments (start_date=now, period_as_timedelta, time_of_day, number_of_meetings)\n",
    "- the function should then return a list of datetimes for a series of meetings that should take place from start_date and evenly distributed throughout the period.\n",
    "- create another list of number of attendents, that was actually there at each meeting.\n",
    "- create a bar plot of attendance through the series of meetings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas for Time Series and Data Frames\n",
    "\n",
    "Pandas is -similar to NumPy- another library offering high-level data structures, which enable fast data analyzis. For us, the most important are probably the types `Series` and `DataFrame`, both of which are introduced in the following.  \n",
    "\n",
    "This tutorial is based on the [intro to Pandas:](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "\n",
    "## Pandas vs Numpy\n",
    "1. In pandas we have 1D Series and 2D DataFrame in numpy we have multi dimensional ndArrays\n",
    "2. In DataFrame we have column names (like in sql) in ndArrays we are data slicing based in indices\n",
    "3. In DataFrame we can have multiple datatypes in different columns\n",
    "![](images/pandas_vs_numpy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pandas --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will refer to Panda's classes and functions often in code, we usually import the module as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Series`\n",
    "\n",
    "A `Series` is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index.\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/dsintro.html#series\n",
    "\n",
    "You can create a Series by passing a list of values, letting Pandas create a default integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       3\n",
      "2       5\n",
      "3     NaN\n",
      "4    seks\n",
      "5       8\n",
      "dtype: object \n",
      "---------------------\n",
      "6    seks\n",
      "5     fem\n",
      "4    fire\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 'seks', 8])\n",
    "print(s,'\\n---------------------')\n",
    "s = pd.Series(['seks','fem','fire'],[6,5,4])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following example introducing `Series` we will collect some open data from the World Bank, see http://data.worldbank.org/?locations=DK-UY. This dataset includes a plethora of interesting data. However, for this example we will focus on the *CO2 emissions*.\n",
    "\n",
    "First, we have to download the data. We do this by writing the response to a request to the World Bank API into a file. As denoted in the response header, we receive a ZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# url = 'http://api.worldbank.org/v2/en/country/DNK;URY' \n",
    "# response = requests.get(url, params={'downloadformat': 'csv'})\n",
    "url = 'http://api.worldbank.org/v2/en/indicator/EN.ATM.CO2E.KT?downloadformat=csv'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response.headers)\n",
    "\n",
    "fname = response.headers['Content-Disposition'].split('=')[1]\n",
    "\n",
    "if response.ok:  # status_code == 200:\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(response.content)   \n",
    "print('-----------------')\n",
    "print('Downloaded {}'.format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -ltrh | tail\n",
    "#man ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can resort to the standard libraries `zipfile` module to uncompress the downloaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zipfile.ZipFile(fname, 'r').extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -ltrh | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can make use of the `glob` module to glob for certain file patterns. We will store the filename of the CSV file we are interested in, in a variable called `local_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# glob is useful in any situation where your program needs to look for a list of files on the filesystem with names matching a pattern. If you need a list of filenames that all have a certain extension, prefix, or any common string in the middle, use glob instead of writing code to scan the directory contents yourself.\n",
    "\n",
    "local_file = glob('./*API_EN*.csv')[0]\n",
    "local_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A small detour...\n",
    "\n",
    "### Collecting information on the CLI\n",
    "\n",
    "To see the header of the file that is of our interest, we can use the `head` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head ./*API_EN.ATM.CO2*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the actual CSV header is on line five. To extract only the header row, we can use the stream editor *sed*, see `man sed`. The argument `'5!d'` tells `sed`, that we are only interested in the fifth line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# sed is a cli application that can filter text from pipeline (inputstream or a file)\n",
    "# Sed Linux command doesnâ€™t update your data. It only sends the changed text to STDOUT\n",
    "# To know more about the sed tool: https://www.geeksforgeeks.org/sed-command-in-linux-unix-with-examples/\n",
    "sed '5!d' API_EN.ATM.CO2E.KT_DS2_en_csv_v2_10473877.csv # sed delete all lines except line 5 (sed '5d' filename.ext (would delete only line 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the two lines -one for Denmark and one for Uruguay repectively- holding the CO2 emission in tons, we can use the grep command, see `man grep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "grep -E \"DNK|URY\" API_EN.ATM.CO2E.KT_DS2_en_csv_v2_10473877.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing OS Commands from Python\n",
    "\n",
    "\n",
    "With the help of the `subprocess` module allows us to execute shell commands and to read what the process was writing to standard out and standard error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "cmd = 'sed 5!d {}'.format(local_file).split()\n",
    "out, err = subprocess.Popen(cmd, stdout=subprocess.PIPE, \n",
    "                            stderr=subprocess.STDOUT).communicate()\n",
    "# Since we are getting the output as a byte literal, we have to decode it into string\n",
    "header_cols = out.splitlines()[0].decode('UTF-8').split(',')\n",
    "header_cols = [h.replace('\"', '') for h in header_cols]\n",
    "print(header_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -ltr *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get in a similar way the line of the CSV file containing the time series corresponding to Danmark's and Uruguay's CO2 emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "cmd = ['grep', '-E', 'DNK|URY', local_file]\n",
    "out, err = subprocess.Popen(cmd, stdout=subprocess.PIPE, \n",
    "                            stderr=subprocess.STDOUT).communicate()\n",
    "lines = out.decode('UTF-8').splitlines()\n",
    "lines = [l.split(',') for l in lines]\n",
    "lines = [[c.replace('\"', '') for c in l] for l in lines]\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Pandas `Series` are one-dimensional labeled arrays, we are now ready to go to create two time series of CO2 emissions for Danmark and Uruguay repectively.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header_cols)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data and the corresponding indexes are still all strings we have to convert them to floats and integers repectively. We do so using two different mechanisms. Once, creation of typed NumPy arrays and on the other hand via a Pandas method `convert_objects`, which converts strings to numerical values of a suitable type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference to check graph: https://www.klimadebat.dk/grafer_co2udledning.php\n",
    "header_cols[4:-1]\n",
    "lines[0][4:-1]\n",
    "\n",
    "ts_dk = pd.Series(lines[0][4:-1], index=np.asarray(header_cols[4:-1], dtype=int))\n",
    "ts_dk = pd.to_numeric(ts_dk)\n",
    "ts_dk.loc[1960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dk.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a time series for the corresponding Uruguaian time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_ury = pd.Series(lines[1][4:-1], index=np.asarray(header_cols[4:-1], dtype=int))\n",
    "ts_ury = pd.to_numeric(ts_ury)\n",
    "ts_ury.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DataFrame`\n",
    "\n",
    "Since `Series` are one-dimensional arrays, we have to create a `DataFrame` if we wanted to combine our two previous `Series` objects `ts_dk` and `ts_ur`.Since `Series` are one-dimensional arrays, we have to create a `DataFrame` if we wanted to combine our two previous `Series` objects `ts_dk` and `ts_ur`. \n",
    "\n",
    "A `DataFrame` is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or **a dict of Series objects**.\n",
    "\n",
    "In the following we concatenate two `Series`to form a `DataFrame`.\n",
    "\n",
    "We will use pandas concat() method [get a good explanation here](https://www.tutorialspoint.com/python_pandas/python_pandas_concatenation.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.concat([ts_dk, ts_ury], axis=1, keys=['DNK', 'URY']) # axis=0 is default (concats like sql UNION) axis=1 concats the data along the x axis\n",
    "#print(ts)\n",
    "#print(type(ts))\n",
    "ts.plot()\n",
    "#ts.DNK\n",
    "#print(ts)\n",
    "#ts['DNK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on `DataFrame`s can be found here:\n",
    "http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n",
    "\n",
    "Similar to, we can create `DataFrame`s by giving the data for the values and indexes explicitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20180302', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since we do not want to work on random example data. We will have a look on the military expenditures of some countries in the world. We will use this data to exemplify usage of Pandas' `DataFrame` methods.\n",
    "\n",
    "Again, we will receive the data from the World Bank.\n",
    "http://data.worldbank.org/indicator/MS.MIL.XPND.CN?locations=DK-CN-US-RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "url = 'http://api.worldbank.org/v2/en/indicator/MS.MIL.XPND.CN'\n",
    "\n",
    "response = requests.get(url, params={'downloadformat': 'csv'})\n",
    "fname = response.headers['Content-Disposition'].split('=')[1]\n",
    "\n",
    "if response.ok:  # status_code == 200:\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(response.content)   \n",
    "\n",
    "print('Downloaded {}',fname)\n",
    "#print('Downloaded {}'.format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "zipfile.ZipFile(fname, 'r').extractall('.')\n",
    "os.remove(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -ltrh | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "\n",
    "milit_files = glob('API_MS.MIL.XPND.CN_DS2_en_csv_v2_10418495.csv')\n",
    "expenditure_csv = milit_files[0]\n",
    "expenditure_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head ./Metadata_Country_API_MS.MIL.XPND.CN_DS2_en_csv_v2_10418495.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use Pandas' `read_csv` function to read the downloaded CSV file directly. Note that we have to skip the first four rows as they do not contain data we are interested in, see keyword argument `skiprows=4`.\n",
    "\n",
    "Reading the CSV file like this returns a `DataFrame` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "expenditures = pd.read_csv(expenditure_csv, skiprows=4)\n",
    "expenditures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Data in a `DataFrame`\n",
    "\n",
    "### Selection by Column Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures['Country Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by Indexes\n",
    "\n",
    "In the following we index the third row directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albania = expenditures.iloc[3]\n",
    "print(albania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures.iloc[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expenditures.iloc[3:5, 4:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Indexing\n",
    "\n",
    "Similar to NumPy, you can use boolean arrays for indexing. That is, you can use boolean expressions directly for indexing.\n",
    "\n",
    "In the following we assign `expenditures` to `df`as the latter is shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = expenditures\n",
    "\n",
    "df[df['Country Name'] == 'Denmark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `isin()` method for filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Country Name'].isin(['United States', 'China', 'Denmark', 'Russian Federation'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a `DataFrame` of all country codes for the four countries, which we want to study further in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_code_df = df[df['Country Name'].isin(['United States', 'China', \n",
    "                                        'Denmark', 'Russian Federation'])]['Country Code']\n",
    "c_code_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot plot the time series of military expenditures directly in a meaningful way as we would like to have the years on the y-axis but in the selection of our `DataFrame`, the year numbers are column names. Consequently, we have to transpose our `DataFrame`, see `T` function.\n",
    "\n",
    "Note, that the expenditures are given in `LUC` in the World Bank data set. That is, in currency of the corresponding country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ts_df = df.iloc[c_code_df.index, 31:-1].T\n",
    "ts_df = ts_df.rename(columns=dict(c_code_df))\n",
    "ts_df\n",
    "ts_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this plot may be a bit misleading, we will 'normalize' all expeditures to Euro, so that they are better comparible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# http://www.ecb.europa.eu/stats/policy_and_exchange_rates/euro_reference_exchange_rates/html/index.en.html#dev\n",
    "response = requests.get('http://www.ecb.europa.eu/stats/eurofxref/eurofxref-daily.xml')\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "xml = BeautifulSoup(response.text, 'html5lib')\n",
    "rate_list = xml.cube.cube.findAll(\"cube\") # [0]['rate']\n",
    "\n",
    "currency = ['USD', 'DKK', 'RUB', 'CNY']\n",
    "rate_dict = dict.fromkeys(currency)\n",
    "for r in rate_list:\n",
    "    if r['currency'] in currency:\n",
    "        rate_dict[r['currency']] = float(r['rate'])\n",
    "        print(r['rate'])\n",
    "rate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df['DNK'] = ts_df['DNK'] / rate_dict['DKK']\n",
    "ts_df['USA'] = ts_df['USA'] / rate_dict['USD']\n",
    "ts_df['CHN'] = ts_df['CHN'] / rate_dict['CNY']\n",
    "ts_df['RUS'] = ts_df['RUS'] / rate_dict['RUB']\n",
    "ts_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS!!!** Be careful, the graph above is still not really well suited for comparison as currency exchange rates are not fix. However, the code above normalizes just relying on the most current exchange rate from the European Central Bank. See the exercise block in the bottom for how to fix that isuue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS\n",
    "\n",
    "In case you have to sort the data in your `DataFrames` see the methods `sort_index` and `sort_values`.\n",
    "\n",
    "\n",
    "```python\n",
    "df.sort_index(axis=1, ascending=True)\n",
    "df.sort_values(by='Country Code')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
